### Web Scraping: IntroducciÃ³n PrÃ¡ctica

## ğŸ“Œ Objetivo Principal
Proporcionar las herramientas esenciales para realizar **web scraping** de forma autÃ³noma y superar las barreras iniciales de la programaciÃ³n.

## ğŸ“– Objetivos EspecÃ­ficos
### FamiliarizaciÃ³n con el Entorno de Desarrollo
- ConfiguraciÃ³n del entorno de trabajo
- IntroducciÃ³n a Jupyter Notebook
- GestiÃ³n de paquetes y dependencias

### Dominio de Herramientas BÃ¡sicas
- Jupyter Notebook como entorno interactivo
- Pandas para manipulaciÃ³n de datos
- Requests y BeautifulSoup para procesamiento HTML

### Habilidades PrÃ¡cticas
- ExtracciÃ³n de datos estructurados
- AutomatizaciÃ³n de procesos de recolecciÃ³n de datos
- AnÃ¡lisis bÃ¡sico de datos web

---

## ğŸŒ Estructura de la SesiÃ³n
1. Web scraping y sus implicaciones
2. QuÃ© es Python
3. Principales librerÃ­as de Python para Scraping
4. Consideraciones antes de hacer scraping
5. Proceso general del web scraping
6. Entornos de desarrollo
7. Comandos principales y shortcuts
8. Recursos y materiales (fuentes pÃºblicas)
9. Git y creaciÃ³n de entorno
10. Primeros pasos de programaciÃ³n con Python

---

## ğŸ›  Web Scraping y sus Implicaciones
El **web scraping** es la tÃ©cnica de extracciÃ³n automatizada de datos de sitios web.

**Ejemplo:** Obtener los titulares de noticias desde una web.
```python
import requests
from bs4 import BeautifulSoup

url = "https://news.ycombinator.com/"

headers = {"User-Agent": "Mozilla/5.0"}
response = requests.get(url, headers=headers)

soup = BeautifulSoup(response.text, 'html.parser')

titles = soup.select('span.titleline > a')

for i, title in enumerate(titles[:5]):
    print(f"{i+1}. {title.text}")
```

---

## ğŸ QuÃ© es Python
Python es un lenguaje de programaciÃ³n interpretado creado por Guido van Rossum en 1991. Se caracteriza por:
- Ser fÃ¡cil de aprender
- Tener una gran cantidad de librerÃ­as disponibles
- Ser interactivo y multiplataforma
- Ser de cÃ³digo libre
- Ser orientado a objetos

---

## ğŸ“š Principales LibrerÃ­as de Python para Scraping
- **Requests**: Para hacer peticiones HTTP
- **BeautifulSoup**: Para analizar HTML
- **Scrapy**: Framework para scraping avanzado
- **Selenium**: Para interactuar con pÃ¡ginas dinÃ¡micas (JavaScript)

**Ejemplo con Requests:**
```python
import requests

response = requests.get("https://api.github.com/users/sergi-ub")
print(response.json()) 

```

---

## âš ï¸ Consideraciones antes de hacer Scraping
Antes de hacer scraping:
âœ… **Revisar `robots.txt`**: Indica quÃ© estÃ¡ permitido.
âœ… **Leer los tÃ©rminos de uso** del sitio web.
âŒ **No abusar** de las peticiones para evitar bloqueos.

**Ejemplo de `robots.txt` bÃ¡sico:**
```plaintext
User-agent: *
Disallow: /private/
Allow: /
```

**Ver robots.txt con Python:**
```python
url = "https://github.com/robots.txt"
print(requests.get(url).text)
```

---

## ğŸ”„ Proceso General del Web Scraping
1. ObtenciÃ³n del contenido HTML de la pÃ¡gina web.
2. ExtracciÃ³n de la informaciÃ³n (parsing).
3. TransformaciÃ³n.
4. Almacenamiento.
5. Ir a otra pÃ¡gina web y repetir el proceso (crawling).

---

## ğŸ’» Entornos de Desarrollo
- **Google Colab**
- **Visual Studio Code**
- **Jupyter Notebook**

### ğŸ‘¾ Comandos de Terminal Ãštiles
```bash
python --version  # Muestra la versiÃ³n de Python instalada
conda list  # Lista los paquetes en el entorno activo
pip list  # Lista los paquetes instalados con pip
pip install nombre_paquete  # Instala un paquete con pip
pip freeze > requirements.txt  # Guarda los paquetes en un archivo
pip install -r requirements.txt  # Instala paquetes desde un archivo
```

---

## â© Atajos Ãštiles en Jupyter Notebook
- `Ctrl + Enter` â†’ Ejecuta la celda sin moverse a la siguiente.
- `Alt + Enter` â†’ Ejecuta la celda y crea una nueva debajo.
- `A` â†’ Inserta una celda arriba.
- `B` â†’ Inserta una celda abajo.
- `M` â†’ Convierte la celda en Markdown.
- `Y` â†’ Convierte la celda en cÃ³digo.
- `D D` â†’ Elimina la celda seleccionada.
- `Z` â†’ Deshace la eliminaciÃ³n de una celda.
- `Shift + M` â†’ Fusiona la celda actual con la siguiente.
- `Ctrl + S` â†’ Guarda el notebook.

---

## ğŸ—‚ï¸ Almacenamiento de Datos
- **CSV**: Datos tabulares.
- **JSON**: Formato estructurado.
- **Bases de datos**: SQL, MongoDB.

**Ejemplo: Guardar datos en CSV**
```python
import csv

data = [['TÃ­tulo', 'URL'], ['Ejemplo', 'https://example.com']]

with open('datos.csv', 'w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerows(data)
```

---

## ğŸ“Œ Recursos Recomendados
- **Kaggle**: [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)
- **UCI Machine Learning Repository**: [https://archive.ics.uci.edu/ml/index.php](https://archive.ics.uci.edu/ml/index.php)
- **Workshop sobre Data Science**: [https://github.com/alabarga/DataScienceWorkshop-BS]
- **Pandas Workshop**: [https://github.com/stefmolin/pandas-workshop]


---





```python

```
